{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clickAnalyzer(inputFileFolder,outputFileFolder,userSessionFile,sessionOrCluster,cluster='None',app_name = 'ORA_FSCM_UIAPP',interestedClick='None',regionViewId='None',\n",
    "                  delta=3,clickidPattern='None',userFilter='None',highlightEdgeCount=2,\n",
    "                  date='None',totalTimeThreshold='None'):\n",
    "        import os\n",
    "        import glob\n",
    "        import pandas as pd\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Code to read all log files\n",
    "        log=pd.DataFrame()\n",
    "        \n",
    "        \n",
    "        if inputFileFolder.endswith(\".log\") == True:\n",
    "            log = pd.read_csv(inputFileFolder,sep=r'\\\\t', engine='python',header=None,names='a')\n",
    "        else:\n",
    "            path =inputFileFolder\n",
    "            filenames = glob.glob(path + \"/*.log\")\n",
    "            for filename in filenames:\n",
    "                print(\"Log Files got : \", filename)\n",
    "                if os.stat(filename).st_size != 0 :\n",
    "                    f = pd.read_csv(filename, sep=r'\\\\t', engine='python', header=None, names='a')                \n",
    "                    log = log.append(f, ignore_index=True)\n",
    "        \n",
    "        if (len(log) == 0):\n",
    "            print(\"Given input dir is empty or no .log files present. Exiting\")\n",
    "            return\n",
    "        else:\n",
    "            clickFile = log\n",
    "            print(\"Total lines in consolidated log file to be processed, before any filters : \", log.shape)\n",
    "        \n",
    "        specificSession = 'None'\n",
    "        cluster = 'None'\n",
    "        \n",
    "        l1 = len(str(sessionOrCluster))\n",
    "        if l1 == 0:\n",
    "            return\n",
    "        else:\n",
    "            if (l1 ==1) or (l1==2) or (l1==3):\n",
    "                cluster = int(sessionOrCluster)\n",
    "                print(\"Cluster chosen : \", cluster)\n",
    "            elif l1 > 2:\n",
    "                cluster = 'None'\n",
    "                specificSession = str(sessionOrCluster)\n",
    "                s_list = specificSession.split(\"^\")\n",
    "                specificSession = '\\^'.join(s_list)\n",
    "                print(\"Specific session chosen : \",specificSession )\n",
    "        \n",
    "#        cd $logFilePath\n",
    "\n",
    "        import re\n",
    "        import numpy as np\n",
    "        from graphviz import Digraph\n",
    "        from collections import defaultdict\n",
    "        import math\n",
    "\n",
    "        output_graph_name = 'ClickGraph' #outputFile[outputFile.rindex(\"\\\\\")+1:outputFile.rfind(\".\")]+\"-graph.jpeg\"\n",
    "        \n",
    "        # Code to read all log files\n",
    "        l=clickFile[clickFile.a.str.contains(app_name)]\n",
    "        #l = pd.read_csv(clickFile, sep=r'\\\\t', engine='python', header=None, names='a')\n",
    "        o = pd.DataFrame()\n",
    "        o = pd.read_csv(userSessionFile)\n",
    "        \n",
    "        #For Specific session\n",
    "        if specificSession != 'None':\n",
    "            withspecificSession = l[l.a.str.contains(specificSession)]\n",
    "            if (len(withspecificSession) < 1 ):\n",
    "                print(\"Chosen Session is not present, exiting !\")\n",
    "                return\n",
    "        else:\n",
    "            withspecificSession = l\n",
    "            \n",
    "        #change1 withChcid = withspecificSession[withspecificSession.a.str.contains(\"CH_CID\")]\n",
    "        \n",
    "        \n",
    "        withChcnm = withspecificSession[withspecificSession.a.str.contains(\"CH_CNM\")]\n",
    "        \n",
    "        #uifscm = withChcnm[withChcnm.a.str.contains(app_name)]\n",
    "        \n",
    "        \n",
    "        remAutoclicks = withChcnm[withChcnm.a.str.contains(\"em_monitoring\") == False]\n",
    "        \n",
    "\n",
    "        \n",
    "        if regionViewId != 'None':\n",
    "            print(\"Region View chosen : \", regionViewId)\n",
    "            prodSpecific = remAutoclicks[remAutoclicks.a.str.contains(regionViewId)]\n",
    "        else:\n",
    "            prodSpecific = remAutoclicks\n",
    "        \n",
    "\n",
    "        if clickidPattern != 'None':    \n",
    "            print(\"clickIdPattern chosen:\",clickidPattern)\n",
    "            specificClickIds = prodSpecific[prodSpecific.a.str.contains(clickidPattern)]\n",
    "        else:\n",
    "            specificClickIds = prodSpecific\n",
    "\n",
    "        log = specificClickIds\n",
    "        \n",
    "        if specificSession != 'None':\n",
    "            log = log[log.a.str.contains(specificSession)]\n",
    "\n",
    "                ####### Filter to process only given cluster's sesions #######################\n",
    "        sessions_to_process = list()        \n",
    "        if cluster != 'None' :       \n",
    "            str_sessions_to_process= str((o.DSID.loc[o['Cluster'] == cluster]).tolist())\n",
    "            str_sessions_to_process=str_sessions_to_process.replace(\"'\",\"\")\n",
    "            sessions_to_process = str_sessions_to_process[1:-1].replace(\" \",\"\").split(',')\n",
    "            print(\"Sessions to be processed : \", sessions_to_process)\n",
    "        \n",
    "        if len(sessions_to_process) != 0 :\n",
    "#             criterion = lambda row: withspecificSession['DSID'] in sessions_to_process\n",
    "#             w = withspecificSession[withspecificSession.apply(criterion, axis=1)]\n",
    "            print(\"Data size before cluster filter : \", log.shape, \" ..\", \"Applying filter of session: \", sessions_to_process)\n",
    "            log1 = pd.DataFrame()\n",
    "            for i,j in enumerate(sessions_to_process):\n",
    "                log1 = log1.append(log[log.a.str.contains(j)])\n",
    "            log = log1                     \n",
    "            print(\"Data size after cluster filter : \", log.shape)       \n",
    "            \n",
    "            \n",
    "        def getProcessedData(row):\n",
    "            a = row.str.split('\\] \\[')[0]       \n",
    "            for st in a:        \n",
    "                b = st.split(':')\n",
    "                if b[0].find('2019') != -1 : # to check for 2016 kind of..\n",
    "                    TIME.append(str(b[0]+\":\"+b[1]+\":\"+b[2]).replace(\"[\",''))            \n",
    "                if(\"APP\" == b[0]):\n",
    "                    APP.append(b[1].strip())\n",
    "\n",
    "#                 if(\"userId\" == b[0]):\n",
    "#                     userId.append(b[1].strip())\n",
    "\n",
    "#                 if( \"ecid\" == b[0] ):\n",
    "#                     ecid.append(b[1].strip()) #+':'+b[2].strip()\n",
    "\n",
    "                if(\"DSID\" == b[0]):\n",
    "                    DSID.append(b[1].strip())\n",
    "\n",
    "                if(\"CH_TTT\" == b[0]):\n",
    "                    CH_TTT.append(b[1].strip())\n",
    "\n",
    "#                 if(\"CH_CET\" == b[0]):\n",
    "#                     CH_CET.append(b[1].strip())\n",
    "\n",
    "#                 if(\"CH_CMP\" == b[0]):\n",
    "#                     CH_CMP.append(b[1].strip())\n",
    "\n",
    "                if(\"CH_CNM\" == b[0]):\n",
    "                    CH_CNM.append(b[1].strip())\n",
    "\n",
    "#                 if(\"CH_TYP\" == b[0]):\n",
    "#                     CH_TYP.append(b[1].strip())\n",
    "\n",
    "#                 if(\"CH_WID\" == b[0]):\n",
    "#                     CH_WID.append(b[1].strip())\n",
    "\n",
    "#                 if(\"CH_EID\" == b[0]):\n",
    "#                     CH_EID.append(b[1].strip().replace(']', ''))\n",
    "\n",
    "                if(\"CH_RVD\" == b[0]):\n",
    "                    CH_RVD.append(b[1].strip().replace(']', ''))     \n",
    "\n",
    "#                 if(\"CH_RTY\" == b[0]):\n",
    "#                     CH_RTY.append(b[1].strip().replace(']', ''))\n",
    "\n",
    "#                 if(\"CH_CST\" == b[0]):\n",
    "#                     CH_CST.append(b[1].strip().replace(']', ''))\n",
    "\n",
    "#                 if(\"CH_FAM\" == b[0]):\n",
    "#                     CH_FAM.append(b[1].strip().replace(']', ''))\n",
    "\n",
    "                if(\"CH_CID\" == b[0]):\n",
    "                    b.pop(0) #remove \"CH_CID\"\n",
    "                    x = \":\".join(b)\n",
    "                    CH_CID.append(x)\n",
    "\n",
    "        #DSID,TIME,CH_CNM,CH_TYP,CH_TTT, CH_CET, CH_EID, CH_RTY, CH_CST, CH_CID, CH_CMP, CH_WID, CH_RVD, CH_FAM,APP, userId,ecid = ([] for i in range(17))\n",
    "        DSID,TIME,CH_CNM,CH_CID,CH_RVD,APP,CH_TTT= ([] for i in range(7))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for index, row in log.iterrows():\n",
    "            getProcessedData(row)\n",
    "        \n",
    "        \n",
    "        lists = [DSID,TIME,CH_CNM,CH_CID,CH_RVD,APP,CH_TTT]\n",
    "        h = ['DSID','TIME','CH_CNM','CH_CID','CH_RVD','APP','CH_TTT']\n",
    "        result2 = pd.concat([pd.Series(x) for x in lists], axis=1) \n",
    "        result2.columns = h\n",
    "        # #### CUSTOM QUERIES ###################################################\n",
    "\n",
    "        # 1. filter by item note/region view id\n",
    "        # if regionViewId != 'None':\n",
    "        #     result2 = result2.loc[result2['CH_RVD'].str.contains(regionViewId)]\n",
    "        #result2 = result2.loc[result2['CH_CID'].str.contains(\"itemNode_projects_pjt_project_management\")]\n",
    "        #result2 = result2.loc[result2['CH_CID'].str.contains(\"itemNode_projects_projects\")]\n",
    "\n",
    "\n",
    "        # 2. Filter before/after a specific click \n",
    "\n",
    "        if interestedClick != 'None':   ####Interested clicks block starts##################  \n",
    "            print(\"Interested click chosen : \", interestedClick)\n",
    "            r = result2.index[result2.CH_CNM.str.contains(interestedClick)].values    \n",
    "            #print(\"GOT INT CLICK \", r)\n",
    "            stind = 0\n",
    "            endind = len(result2)-1\n",
    "\n",
    "            if len(r) != 0 : # If searched clicks is not found, then report everything\n",
    "        #if interested click hppens more than once, take earliest one as stind and last occurence as endind\n",
    "                 if type(r) == np.ndarray:\n",
    "                    l = len(r)\n",
    "                    stind = r[0]\n",
    "                    endind = r[l-1]\n",
    "                 else:\n",
    "                    stind = r\n",
    "                    enind = r\n",
    "\n",
    "        #compute st end indcides based on delta selected\n",
    "                 if stind-delta >= 0 :\n",
    "                    stind = stind-delta\n",
    "                 else:\n",
    "                    stind = 0\n",
    "\n",
    "                 if endind+delta <= len(result2)-1:\n",
    "                    endind = endind+delta+1 #else endind as is\n",
    "                 else:\n",
    "                    endind = (len(result2))\n",
    "\n",
    "                 result2 = result2[stind : endind]\n",
    "        ####Interested clicks block ends##################\n",
    "\n",
    "\n",
    "        # 3. Filter for specific user\n",
    "        if userFilter != 'None':\n",
    "            print(\"user filter chosen : \", userFilter.shape)\n",
    "            result2 = result2.loc[result2['userId'].str.contains(userFilter)]\n",
    "\n",
    "\n",
    "        # 4. Date filter\n",
    "        if date != 'None':\n",
    "            result2 = result2.loc[result2['TIME'].str.contains(date)]\n",
    "\n",
    "        # 5. Click timings more than threshold\n",
    "        # if totalTimeThreshold != 'None':\n",
    "        #     result2 = result2.loc[np.int(result2['CH_TTT']) > totalTimeThreshold]\n",
    "\n",
    "        #6. Specific Session Id\n",
    "        \n",
    "      \n",
    "        \n",
    "\n",
    "        # #### CUSTOM QUERIES ###################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (len(result2)) < 1 :\n",
    "            print(\"After filters no data to process. Exiting ...\")\n",
    "            return\n",
    "        else:\n",
    "            sort_cols = [\"DSID\",\"TIME\"] #Not sorting assuming we process file by file and in each file its already sorted\n",
    "            f2 = result2[['DSID','TIME','CH_CID','CH_CNM','CH_TTT']]\n",
    "            final_result = f2.sort_values(by=sort_cols, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "            for index, row in final_result.iterrows():              \n",
    "                row['CH_CID'] = row['CH_CID'].replace(row['CH_CID'],re.sub(':*:', '',row['CH_CID'] ) )    \n",
    "\n",
    "\n",
    "            # To hash the unique click ids\n",
    "            col_list = final_result[['CH_CNM']] ## Hash based on chcid vs chcnm\n",
    "            x= pd.DataFrame(final_result[['CH_CID','CH_CNM']])\n",
    "            #col_list.dropna(axis=0,subset=['CH_CNM'],inplace=True)\n",
    "            unique_col_list = col_list.drop_duplicates(keep='first')\n",
    "            unique_col_list.insert(0, 'Key', range(0, len(unique_col_list)))\n",
    "\n",
    "            d1 = pd.merge(unique_col_list,x,how='left',on=['CH_CNM'])\n",
    "\n",
    "            nodedict = d1.set_index('Key')['CH_CNM'].to_dict()\n",
    "\n",
    "\n",
    "            p_final = pd.merge(final_result,unique_col_list,how=\"left\",on=['CH_CNM'])\n",
    "            #print(\"NUMBER OF UNIQUE CLICKS FOUND ...\",p_final.shape)\n",
    "            outfile = open('ClickGraph.csv', 'w')\n",
    "            p_final.to_csv(outfile)\n",
    "            outfile.close()\n",
    "            labels=pd.DataFrame(p_final.CH_CNM)\n",
    "            df3 = pd.DataFrame(columns=['k1','k2','CH_CID'])\n",
    "            df1 = pd.DataFrame(p_final.Key)\n",
    "            df2 = pd.DataFrame(p_final.Key)\n",
    "            df22 = pd.DataFrame(p_final.CH_CID)\n",
    "            df3 = pd.concat([df1,df2,df22],axis=1)\n",
    "            df3.columns= ['k1','k2','CH_CID']\n",
    "            df4 = pd.concat([df3,labels],axis=1)\n",
    "\n",
    "            def isNaN(num):\n",
    "                return num != num\n",
    "\n",
    "            #using graphviz\n",
    "            if outputFileFolder == 'None':\n",
    "                G = Digraph(format='jpeg')\n",
    "            else:\n",
    "                G = Digraph(format='jpeg',directory=outputFileFolder)\n",
    "            G.attr(rankdir='LR')\n",
    "            G.attr('node', shape='circle', width='1', nodesep='0.5')\n",
    "            c = len(df4)\n",
    "            nodelist = []\n",
    "            Gdict = defaultdict(list)\n",
    "            Gkeylabeldict = defaultdict(list)\n",
    "            a = []\n",
    "\n",
    "            for idx, row in df4.iterrows():\n",
    "                curr_key = np.int(row.k1)    \n",
    "                if isNaN(df4.k2.shift(-1)[idx]) == True:\n",
    "                        next_key = df4.k2.shift(-1)[idx]\n",
    "                else:\n",
    "                    next_key = np.int(df4.k2.shift(-1)[idx])    \n",
    "                curr_nodelabel=str(nodedict.get(row.CH_CID))\n",
    "\n",
    "                #prepare node dictionary\n",
    "                if isNaN(curr_key) == False: # 00 here it was next_key _21 nov\n",
    "                    if curr_key in Gdict.keys():           \n",
    "                        if type(Gdict[curr_key]) == list:            \n",
    "                            #if next_key not in np.asarray(Gdict[curr_key]):                                \n",
    "                                Gdict[curr_key].append(next_key)\n",
    "                        elif type(Gdict[curr_key]) == np.int:            \n",
    "                            #if next_key != Gdict[curr_key]:                                \n",
    "                                Gdict[curr_key] = [Gdict[curr_key], next_key]\n",
    "                    else:        \n",
    "                        Gdict.update({curr_key:next_key})\n",
    "\n",
    "                #capture labels of each key\n",
    "                if curr_key not in Gkeylabeldict.keys():\n",
    "\n",
    "                    o  = np.int(len(row.CH_CID))\n",
    "                    Gkeylabeldict[curr_key] = str( row.CH_CID[-10:] )\n",
    "\n",
    "\n",
    "\n",
    "            node1 = [None] * c\n",
    "            node2 = [None] * c\n",
    "            edgecount = [None] * c\n",
    "\n",
    "\n",
    "            def find_element_in_list(element, list_element):\n",
    "                try:\n",
    "                    index_element = list_element.index(element)\n",
    "                    return index_element\n",
    "                except ValueError:\n",
    "                    return -1\n",
    "\n",
    "\n",
    "            def incrementEdgeCount(a,b,l1,l2,l3,d):\n",
    "                a_index = find_element_in_list(a,l1)\n",
    "                b_index = find_element_in_list(b,l2)\n",
    "                edge_index_value = -1\n",
    "\n",
    "                counter=0\n",
    "                for i,j,k in zip(l1,l2,l3):\n",
    "                    if (i == a) and (j == b) and (k != 0):\n",
    "                        edge_index_value = k\n",
    "                        edgecount[counter] = edgecount[counter]+1\n",
    "                        break\n",
    "                    counter = counter+1\n",
    "\n",
    "                if edge_index_value == -1:\n",
    "                    node1[d]=str(a)            \n",
    "                    node2[d]=str(b)  \n",
    "                    edgecount[d]=1\n",
    "            #     if a_index != -1 and b_index != -1:\n",
    "            #         edge_index_value = l3[a_index]\n",
    "\n",
    "            #     if (a_index == b_index) and (a_index != -1) :                                \n",
    "            #         edgecount[a_index] = l3[a_index] + 1\n",
    "            #     else:        \n",
    "            #         node1[d]=str(a)            \n",
    "            #         node2[d]=str(b)  \n",
    "            #         if edge_index_value != -1:            \n",
    "            #             edgecount[d]=edge_index_value+1\n",
    "            #         else:\n",
    "            #             edgecount[d]=1\n",
    "\n",
    "\n",
    "            # #Iterating thru dictionary and creating the graph \n",
    "            idx=0\n",
    "            prevnode = -1\n",
    "            l = len(Gdict)\n",
    "            d=0\n",
    "\n",
    "            #testing\n",
    "            idx=0\n",
    "            CreatedNodeCount=0\n",
    "\n",
    "            nodeOrder=0\n",
    "            for k,v in Gdict.items():    # NODE CREATION       \n",
    "\n",
    "                #if isNaN(nodedict.get(k)) == False :\n",
    "                    if isNaN(nodedict.get(k) ):        \n",
    "                        nlabel = Gkeylabeldict.get(k)  # -- TO DO return back the CH_CID\n",
    "                    else :\n",
    "                        nlabel = nodedict.get(k)    \n",
    "                    if idx == 0:\n",
    "                        nodeOrder = nodeOrder+1\n",
    "                        #print(nodeOrder,\". \",nlabel)\n",
    "                        G.node(str(k),label=str(nodeOrder)+\"\\n\"+nlabel,color='Green',style='filled') #,fixedsize='true',width='2'        \n",
    "                        CreatedNodeCount+=1\n",
    "                    else:\n",
    "                        #print(nodeOrder,\". \",nlabel)\n",
    "                        nodeOrder = nodeOrder+1\n",
    "                        G.node(str(k),label=str(nodeOrder)+\"\\n\"+nlabel,nodesize='10')            \n",
    "                        CreatedNodeCount+=1\n",
    "                    idx+=1\n",
    "\n",
    "            print(\"NUMBER OF UNIQUE NODES CREATED : \", CreatedNodeCount)\n",
    "\n",
    "            for k,v in Gdict.items():  # EDGE CREATION\n",
    "                #print(k,\"-->\",v)\n",
    "                if isNaN(k) == False:\n",
    "                    if type(v) == list :        \n",
    "                        if len(v) == 1 :                                            \n",
    "                            incrementEdgeCount(str(k),str(np.int(v[0]) ),node1,node2,edgecount,d)\n",
    "                            d=d+1\n",
    "                        elif len(v) > 1 :\n",
    "                            for i in v :\n",
    "                                if (isNaN(str(k)) == False) and (isNaN(str(i)) == False or str(i).strip() != \"nan\") and (str(k) != str(i) ): # removing self-references                        \n",
    "                                    incrementEdgeCount(str(k),str(i),node1,node2,edgecount,d)\n",
    "                                    d=d+1\n",
    "                    else:\n",
    "                        if isNaN(v) == False :\n",
    "                            #if (str(k) != str(np.int(v)) )  :     # removing self-references                           \n",
    "                                incrementEdgeCount(str(k),str(np.int(v)),node1,node2,edgecount,d)\n",
    "                                d=d+1\n",
    "\n",
    "            highestEdge=0\n",
    "            for i,j,k in zip(node1,node2,edgecount):\n",
    "                if i != None and j != None and k != None :        \n",
    "                    if highestEdge < k :\n",
    "                        highestEdge = k\n",
    "\n",
    "            # for i,j,k in zip(node1,node2,edgecount):\n",
    "            #     print(i,\"-->\",j,\"-->\",k)\n",
    "            for i,j,k in zip(node1,node2,edgecount):\n",
    "                if i != None and j != None and k != None :        \n",
    "                    #if k > 1:\n",
    "                    if (k == highestEdge) and (highestEdge >= highlightEdgeCount):\n",
    "                            G.edge(str(i),str(j),label=str((k)),color=\"Red\",style=\"filled\")\n",
    "                    else:\n",
    "                        print(\"drawing edge : \", str(i),\"==>\",str(j))\n",
    "                        if (str(i) != 'nan' and str(j) != 'nan'):\n",
    "                            G.edge(str(i),str(j),label=str((k)))\n",
    "\n",
    "            G.render(output_graph_name,view=True)\n",
    "            print(\"Graph creation completed ! ..\", output_graph_name + \". Time taken : \",round(time.time() - start_time),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clickAnalyzer(inputFileFolder='D:\\\\ASTUDY\\\\AIML\\\\programs\\\\Fleet\\\\FlowLevel\\\\s\\\\UIServer_as1_03-clickhistory-9.log',\n",
    "#               outputFileFolder='D:\\\\ASTUDY\\\\AIML\\\\programs\\\\Fleet\\\\FlowLevel\\\\s',\n",
    "#               userSessionFile='D:\\\\ASTUDY\\\\AIML\\\\programs\\\\Fleet\\\\FlowLevel\\\\s\\\\output-usersessions.csv',\n",
    "#               sessionOrCluster='0000MY13Men7q25prOs1yY1S91ZE000VK1')\n",
    "\n",
    "import sys\n",
    "clickAnalyzer(sys.argv[1],sys.argv[2],sys.argv[3],sys.argv[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
